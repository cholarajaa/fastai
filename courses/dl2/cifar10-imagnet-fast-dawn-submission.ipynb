{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.dataset import *\n",
    "from fastai.fp16 import *\n",
    "from fastai.conv_learner import *\n",
    "from pathlib import *\n",
    "from fastai import io\n",
    "import tarfile\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import models\n",
    "import models.cifar10 as cifar10models\n",
    "from distributed import DistributedDataParallel as DDP\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# print(models.cifar10.__dict__)\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(models.__dict__[name]))\n",
    "\n",
    "cifar10_names = sorted(name for name in cifar10models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(cifar10models.__dict__[name]))\n",
    "\n",
    "model_names = cifar10_names + model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(models.cifar10.__dict__)\n",
    "#print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--rank'], dest='rank', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help=\"Used for multi-process training. Can either be manually set or automatically set by using 'python -m multiproc'.\", metavar=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage: python run_fastai.py /home/paperspace/ILSVRC/Data/CLS-LOC/ -a resnext_50_32x4d --epochs 1 -j 4 -b 64 --fp16\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Cifar10 Training')\n",
    "parser.add_argument('data', metavar='DIR',\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--save-dir', type=str, default=Path.home()/'imagenet_training',\n",
    "                    help='Directory to save logs and models.')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet56',\n",
    "                    choices=model_names,\n",
    "                    help='model architecture: ' +\n",
    "                    ' | '.join(model_names) +\n",
    "                    ' (default: resnet56)')\n",
    "parser.add_argument('-dp', '--data-parallel', action='store_true', help='Use DataParallel')\n",
    "parser.add_argument('-j', '--workers', default=7, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=1, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--cycle-len', default=95, type=float, metavar='N',\n",
    "                    help='Length of cycle to run')\n",
    "# parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "#                     help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=512, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 512)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.8, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "# parser.add_argument('--print-freq', '-p', default=10, type=int,\n",
    "#                     metavar='N', help='print frequency (default: 10)')\n",
    "# parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "#                     help='path to latest checkpoint (default: none)')\n",
    "# parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "#                     help='evaluate model on validation set')\n",
    "parser.add_argument('--pretrained', dest='pretrained', action='store_true', help='use pre-trained model')\n",
    "parser.add_argument('--fp16', action='store_true', help='Run model fp16 mode.')\n",
    "parser.add_argument('--use-tta', default=False, type=bool, help='Validate model with TTA at the end of traiing.')\n",
    "parser.add_argument('--sz',       default=32, type=int, help='Size of transformed image.')\n",
    "# parser.add_argument('--decay-int', default=30, type=int, help='Decay LR by 10 every decay-int epochs')\n",
    "parser.add_argument('--use-clr', default='10,13.68,0.95,0.85', type=str,\n",
    "                    help='div,pct,max_mom,min_mom. Pass in a string delimited by commas. Ex: \"20,2,0.95,0.85\"')\n",
    "parser.add_argument('--loss-scale', type=float, default=128,\n",
    "                    help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "parser.add_argument('--warmup', action='store_true', help='Do a warm-up epoch first')\n",
    "parser.add_argument('--prof', dest='prof', action='store_true', help='Only run a few iters for profiling.')\n",
    "parser.add_argument('--dist-url', default='file://sync.file', type=str,\n",
    "                    help='url used to set up distributed training')\n",
    "parser.add_argument('--dist-backend', default='nccl', type=str, help='distributed backend')\n",
    "parser.add_argument('--world-size', default=1, type=int,\n",
    "                    help='Number of GPUs to use. Can either be manually set ' +\n",
    "                    'or automatically set by using \\'python -m multiproc\\'.')\n",
    "parser.add_argument('--rank', default=0, type=int,\n",
    "                    help='Used for multi-process training. Can either be manually set ' +\n",
    "                    'or automatically set by using \\'python -m multiproc\\'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "        return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))\n",
    "\n",
    "class TorchModelData(ModelData):\n",
    "    def __init__(self, path, sz, trn_dl, val_dl, aug_dl=None):\n",
    "        super().__init__(path, trn_dl, val_dl)\n",
    "        self.aug_dl = aug_dl\n",
    "        self.sz = sz\n",
    "\n",
    "def download_cifar10(data_path):\n",
    "    # (AS) TODO: put this into the fastai library\n",
    "    def untar_file(file_path, save_path):\n",
    "        if file_path.endswith('.tar.gz') or file_path.endswith('.tgz'):\n",
    "            obj = tarfile.open(file_path)\n",
    "            obj.extractall(save_path)\n",
    "            obj.close()\n",
    "            os.remove(file_path)\n",
    "\n",
    "    cifar_url = 'http://files.fast.ai/data/cifar10.tgz' # faster download\n",
    "    # cifar_url = 'http://pjreddie.com/media/files/cifar.tgz'\n",
    "    io.get_data(cifar_url, args.data+'/cifar10.tgz')\n",
    "    untar_file(data_path+'/cifar10.tgz', data_path)\n",
    "    # Loader expects train and test folders to be outside of cifar10 folder\n",
    "    shutil.move(data_path+'/cifar10/train', data_path)\n",
    "    shutil.move(data_path+'/cifar10/test', data_path)\n",
    "\n",
    "def torch_loader(data_path, size):\n",
    "    if not os.path.exists(data_path+'/train'): download_cifar10(data_path)\n",
    "\n",
    "    # Data loading code\n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'test')\n",
    "    normalize = transforms.Normalize(mean=[0.4914 , 0.48216, 0.44653], std=[0.24703, 0.24349, 0.26159])\n",
    "    tfms = [transforms.ToTensor(), normalize]\n",
    "\n",
    "    scale_size = 40\n",
    "    padding = int((scale_size - size) / 2)\n",
    "    train_tfms = transforms.Compose([\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(scale_size),\n",
    "        transforms.ColorJitter(.25,.25,.25),\n",
    "        transforms.RandomRotation(2),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tfms)\n",
    "    val_tfms = transforms.Compose(tfms)\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(traindir, train_tfms)\n",
    "    val_dataset = datasets.ImageFolder(valdir, val_tfms)\n",
    "\n",
    "    train_sampler = (torch.utils.data.distributed.DistributedSampler(train_dataset) if args.distributed else None)\n",
    "    val_sampler = (torch.utils.data.distributed.DistributedSampler(val_dataset) if args.distributed else None)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=args.batch_size*2, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True, sampler=val_sampler)\n",
    "\n",
    "    aug_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(valdir, train_tfms),\n",
    "        batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    train_loader = DataPrefetcher(train_loader)\n",
    "    val_loader = DataPrefetcher(val_loader)\n",
    "    aug_loader = DataPrefetcher(aug_loader)\n",
    "    if args.prof:\n",
    "        train_loader.stop_after = 200\n",
    "        val_loader.stop_after = 0\n",
    "\n",
    "    data = TorchModelData(data_path, args.sz, train_loader, val_loader, aug_loader)\n",
    "    if train_sampler: \n",
    "        data.trn_sampler = train_sampler\n",
    "        data.val_sampler = val_sampler\n",
    "    return data\n",
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5(output, target):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    top5 = 5\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(top5, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct_k = correct[:top5].view(-1).float().sum(0, keepdim=True)\n",
    "    return correct_k.mul_(1.0 / batch_size)\n",
    "\n",
    "\n",
    "class ImagenetLoggingCallback(Callback):\n",
    "    start_time = 0\n",
    "    def __init__(self, save_path, print_every=50):\n",
    "        super().__init__()\n",
    "        self.save_path=save_path\n",
    "        self.print_every=print_every\n",
    "        self.start_time = datetime.now()\n",
    "    def on_train_begin(self):\n",
    "        self.batch = 0\n",
    "        self.epoch = 0\n",
    "        self.f = open(self.save_path, \"a\", 1)\n",
    "        self.log(\"epoch\\thours\\ttop1Accuracy\")\n",
    "    def on_epoch_end(self, metrics):\n",
    "        current_time = datetime.now()\n",
    "        time_diff = current_time - self.start_time\n",
    "        log_str = f'{self.epoch}\\t{float(time_diff.total_seconds() / 3600.0)}\\t{100 * metrics[1]}'\n",
    "        #for (k,v) in zip(['val_loss', 'acc'], metrics): if k=='acc': log_str += f'\\t{k}:{v}'\n",
    "        self.log(log_str)\n",
    "        self.epoch += 1\n",
    "    def on_batch_end(self, metrics):\n",
    "        self.last_loss = metrics\n",
    "        self.batch += 1\n",
    "        #if self.batch % self.print_every == 0:\n",
    "            #self.log(f'Epoch: {self.epoch} Batch: {self.batch} Metrics: {metrics}')\n",
    "    def on_train_end(self): self.f.close()\n",
    "    def log(self, string): self.f.write(string+\"\\n\")\n",
    "\n",
    "# Logging + saving models\n",
    "def save_args(name, save_dir):\n",
    "    if (args.rank != 0) or not args.save_dir: return {}\n",
    "\n",
    "    log_dir = f'{save_dir}/training_logs'\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    return {\n",
    "        'best_save_name': f'{name}_best_model',\n",
    "        'cycle_save_name': f'{name}',\n",
    "        'callbacks': [\n",
    "            ImagenetLoggingCallback(f'{log_dir}/{name}_log.txt')\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def save_sched(sched, save_dir):\n",
    "    if (args.rank != 0) or not args.save_dir: return {}\n",
    "    log_dir = f'{save_dir}/training_logs'\n",
    "    sched.save_path = log_dir\n",
    "    sched.plot_loss()\n",
    "    sched.plot_lr()\n",
    "\n",
    "def update_model_dir(learner, base_dir):\n",
    "    learner.tmp_path = f'{base_dir}/tmp'\n",
    "    os.makedirs(learner.tmp_path, exist_ok=True)\n",
    "    learner.models_path = f'{base_dir}/models'\n",
    "    os.makedirs(learner.models_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_input = [\n",
    "    '/home/paperspace/data/cifar10', \n",
    "    '--save-dir', '/home/paperspace/data/cifar_training/preact_test',\n",
    "    '-a', 'wrn_22',\n",
    "    '-b', '512', \n",
    "    '--loss-scale', '512',\n",
    "    '--fp16',\n",
    "    '--cycle-len', '30',\n",
    "    '--use-clr', '20,20,0.95,0.85',\n",
    "    '--wd', '1e-4',\n",
    "    '--lr', '1.5',\n",
    "#     '--train-half' # With fp16, iterations are so fast this doesn't matter\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is important for speed\n",
    "cudnn.benchmark = True\n",
    "global arg\n",
    "args = parser.parse_args(args_input); args\n",
    "if args.cycle_len > 1: args.cycle_len = int(args.cycle_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.distributed = args.world_size > 1\n",
    "args.gpu = 0\n",
    "if args.distributed: args.gpu = args.rank % torch.cuda.device_count()\n",
    "\n",
    "if args.distributed:\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "                            world_size=args.world_size)\n",
    "\n",
    "if args.fp16: assert torch.backends.cudnn.enabled, \"missing cudnn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cifar10models.__dict__[args.arch] if args.arch in cifar10_names else models.__dict__[args.arch]\n",
    "if args.pretrained: model = model(pretrained=True)\n",
    "else: model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "if args.distributed: model = DDP(model)\n",
    "if args.data_parallel:\n",
    "    n_dev = 4\n",
    "    model = nn.DataParallel(model, range(n_dev))\n",
    "    args.batch_size *= n_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = torch_loader(args.data, args.sz)\n",
    "\n",
    "learner = Learner.from_model_data(model, data)\n",
    "learner.crit = F.cross_entropy\n",
    "learner.metrics = [accuracy]\n",
    "if args.fp16: learner.half()\n",
    "\n",
    "if args.prof: args.epochs,args.cycle_len = 1,0.01\n",
    "if args.use_clr: args.use_clr = tuple(map(float, args.use_clr.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FP16(\n",
       "  (module): WideResNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): NetworkBlock(\n",
       "        (layer): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu1): ReLU(inplace)\n",
       "            (conv1): Conv2d(16, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu2): ReLU(inplace)\n",
       "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (convShortcut): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu1): ReLU(inplace)\n",
       "            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu2): ReLU(inplace)\n",
       "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu1): ReLU(inplace)\n",
       "            (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu2): ReLU(inplace)\n",
       "            (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): NetworkBlock(\n",
       "        (layer): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu1): ReLU(inplace)\n",
       "            (conv1): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu2): ReLU(inplace)\n",
       "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (convShortcut): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu1): ReLU(inplace)\n",
       "            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu2): ReLU(inplace)\n",
       "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu1): ReLU(inplace)\n",
       "            (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu2): ReLU(inplace)\n",
       "            (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): NetworkBlock(\n",
       "        (layer): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu1): ReLU(inplace)\n",
       "            (conv1): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu2): ReLU(inplace)\n",
       "            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (convShortcut): Conv2d(192, 384, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu1): ReLU(inplace)\n",
       "            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu2): ReLU(inplace)\n",
       "            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu1): ReLU(inplace)\n",
       "            (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "            (relu2): ReLU(inplace)\n",
       "            (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (5): ReLU(inplace)\n",
       "      (6): AdaptiveConcatPool2d(\n",
       "        (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "        (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "      )\n",
       "      (7): Flatten(\n",
       "      )\n",
       "      (8): Linear(in_features=768, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Conv2d-1',\n",
       "              OrderedDict([('input_shape', [-1, 3, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 432)])),\n",
       "             ('BatchNorm2d-2',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 32)])),\n",
       "             ('ReLU-3',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 16, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-4',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 13824)])),\n",
       "             ('BatchNorm2d-5',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 192)])),\n",
       "             ('ReLU-6',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-7',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 82944)])),\n",
       "             ('Conv2d-8',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1536)])),\n",
       "             ('BasicBlock-9',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-10',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 192)])),\n",
       "             ('ReLU-11',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-12',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 82944)])),\n",
       "             ('BatchNorm2d-13',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 192)])),\n",
       "             ('ReLU-14',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-15',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 82944)])),\n",
       "             ('BasicBlock-16',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-17',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 192)])),\n",
       "             ('ReLU-18',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-19',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 82944)])),\n",
       "             ('BatchNorm2d-20',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 192)])),\n",
       "             ('ReLU-21',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-22',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 82944)])),\n",
       "             ('BasicBlock-23',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('NetworkBlock-24',\n",
       "              OrderedDict([('input_shape', [-1, 16, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-25',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 192)])),\n",
       "             ('ReLU-26',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 96, 32, 32]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-27',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 165888)])),\n",
       "             ('BatchNorm2d-28',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 384)])),\n",
       "             ('ReLU-29',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-30',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 331776)])),\n",
       "             ('Conv2d-31',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 18432)])),\n",
       "             ('BasicBlock-32',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-33',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 384)])),\n",
       "             ('ReLU-34',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-35',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 331776)])),\n",
       "             ('BatchNorm2d-36',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 384)])),\n",
       "             ('ReLU-37',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-38',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 331776)])),\n",
       "             ('BasicBlock-39',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-40',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 384)])),\n",
       "             ('ReLU-41',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-42',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 331776)])),\n",
       "             ('BatchNorm2d-43',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 384)])),\n",
       "             ('ReLU-44',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-45',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 331776)])),\n",
       "             ('BasicBlock-46',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('NetworkBlock-47',\n",
       "              OrderedDict([('input_shape', [-1, 96, 32, 32]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-48',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 384)])),\n",
       "             ('ReLU-49',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 192, 16, 16]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-50',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 663552)])),\n",
       "             ('BatchNorm2d-51',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 768)])),\n",
       "             ('ReLU-52',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-53',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1327104)])),\n",
       "             ('Conv2d-54',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 73728)])),\n",
       "             ('BasicBlock-55',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-56',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 768)])),\n",
       "             ('ReLU-57',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-58',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1327104)])),\n",
       "             ('BatchNorm2d-59',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 768)])),\n",
       "             ('ReLU-60',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-61',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1327104)])),\n",
       "             ('BasicBlock-62',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-63',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 768)])),\n",
       "             ('ReLU-64',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-65',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1327104)])),\n",
       "             ('BatchNorm2d-66',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 768)])),\n",
       "             ('ReLU-67',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Conv2d-68',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 1327104)])),\n",
       "             ('BasicBlock-69',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('NetworkBlock-70',\n",
       "              OrderedDict([('input_shape', [-1, 192, 16, 16]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('BatchNorm2d-71',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 768)])),\n",
       "             ('ReLU-72',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 8, 8]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('AdaptiveMaxPool2d-73',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 1, 1]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('AdaptiveAvgPool2d-74',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 384, 1, 1]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('AdaptiveConcatPool2d-75',\n",
       "              OrderedDict([('input_shape', [-1, 384, 8, 8]),\n",
       "                           ('output_shape', [-1, 768, 1, 1]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Flatten-76',\n",
       "              OrderedDict([('input_shape', [-1, 768, 1, 1]),\n",
       "                           ('output_shape', [-1, 768]),\n",
       "                           ('nb_params', 0)])),\n",
       "             ('Linear-77',\n",
       "              OrderedDict([('input_shape', [-1, 768]),\n",
       "                           ('output_shape', [-1, 10]),\n",
       "                           ('trainable', True),\n",
       "                           ('nb_params', 7690)])),\n",
       "             ('WideResNet-78',\n",
       "              OrderedDict([('input_shape', [-1, 3, 32, 32]),\n",
       "                           ('output_shape', [-1, 10]),\n",
       "                           ('nb_params', 0)]))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f8f487cc1b4b99972cdaf982e12a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/98 [00:08<00:38,  2.08it/s, loss=2.63]\n",
      " 18%|█▊        | 18/98 [00:08<00:38,  2.09it/s, loss=2.61]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      3.257645   nan        0.1473    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.sched.plot(n_skip=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Full size\n",
    "update_model_dir(learner, args.save_dir)\n",
    "sargs = save_args('first_run', args.save_dir)\n",
    "\n",
    "if args.warmup:\n",
    "    learner.fit(args.lr/10, 1, cycle_len=1, wds=args.weight_decay,\n",
    "            use_clr_beta=(100,1,0.9,0.8), loss_scale=args.loss_scale, **sargs)\n",
    "\n",
    "learner.fit(args.lr,args.epochs, cycle_len=args.cycle_len,\n",
    "            wds=args.weight_decay,\n",
    "            use_clr_beta=args.use_clr, loss_scale=args.loss_scale,\n",
    "            **sargs)\n",
    "save_sched(learner.sched, args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.use_tta:\n",
    "    log_preds,y = learner.TTA()\n",
    "    preds = np.mean(np.exp(log_preds),0)\n",
    "    acc = accuracy(torch.FloatTensor(preds),torch.LongTensor(y))\n",
    "    print('TTA acc:', acc)\n",
    "\n",
    "    with open(f'{args.save_dir}/tta_accuracy.txt', \"a\", 1) as f:\n",
    "        f.write(time.strftime(\"%Y-%m-%dT%H:%M:%S\")+f\"\\tTTA accuracty: {acc}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test ground for combining models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
