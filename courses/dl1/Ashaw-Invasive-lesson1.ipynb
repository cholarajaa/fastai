{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification with Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the libraries we need. We'll learn about what each does during the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/invasivespecies/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz=600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Extra steps if NOT using Crestle or our scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The dataset is available at http://files.fast.ai/data/dogscats.zip. You can download it directly on your server by running the following line in your terminal. `wget http://files.fast.ai/data/dogscats.zip`. You should put the data in a subdirectory of this notebook's directory, called `data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = PATH+'train_labels.csv'\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## First look at Plant pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our library will assume that you have *train* and *valid* directories. It also assumes that each dir will have subdirs for each class you wish to recognize (in this case, 'cats' and 'dogs')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!ls {PATH}valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files = !ls {PATH}train | head\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_file = PATH+'train/'+str(df['name'][0])+'.jpg'\n",
    "print(test_file)\n",
    "test_img = plt.imread(test_file)\n",
    "plt.imshow(test_img)\n",
    "# PIL.Image.open(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here is how the raw data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_img[:4,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_map = { k:plt.imread(f'{PATH}train/{k}.jpg').shape for k in df.name }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w, c = zip(*shape_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = plt.figure()\n",
    "# f = plt.subplot(1,2,1, figsize=(2,2))\n",
    "f, [ax1, ax2] = plt.subplots(1,2, figsize=(12,4))\n",
    "ax1.hist(w)\n",
    "# f = plt.subplot(1,2,2, figsize=(2,2))\n",
    "ax2.hist(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Our first model: quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're going to use a <b>pre-trained</b> model, that is, a model created by some one else to solve a different problem. Instead of building a model from scratch to solve a similar problem, we'll use a model trained on ImageNet (1.2 million images and 1000 classes) as a starting point. The model is a Convolutional Neural Network (CNN), a type of Neural Network that builds state-of-the-art models for computer vision. We'll be learning all about CNNs during this course.\n",
    "\n",
    "We will be using the <b>resnet34</b> model. resnet34 is a version of the model that won the 2015 ImageNet competition. Here is more info on [resnet models](https://github.com/KaimingHe/deep-residual-networks). We'll be studying them in depth later, but for now we'll focus on using them effectively.\n",
    "\n",
    "Here's how to train and evalulate a *dogs vs cats* model in 3 lines of code, and under 20 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Uncomment the below if you need to reset your precomputed activations\n",
    "# !rm -rf {PATH}tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df.shape[0]-1\n",
    "val_idxs = get_cv_idxs(n)\n",
    "def get_data(sz,bs):\n",
    "    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "    data = ImageClassifierData.from_csv(path=PATH, folder='train', csv_fname=csv_path, num_workers=4, \n",
    "                                        tfms=tfms, suffix='.jpg', test_name='test', val_idxs=val_idxs, skip_header=True, bs=bs)\n",
    "    return data.resize(sz, 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arch = resnet34\n",
    "data = get_data(sz, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How good is this model? Well, as we mentioned, prior to this competition, the state of the art was 80% accuracy. But the competition resulted in a huge jump to 98.9% accuracy, with the author of a popular deep learning library winning the competition. Extraordinarily, less than 4 years later, we can now beat that result in seconds! Even last year in this same course, our initial model had 98.3% accuracy, which is nearly double the error we're getting just a year later, and that took around 10 minutes to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Analyzing results: looking at pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "3. The most correct labels of each class (ie those with highest probability that are correct)\n",
    "4. The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
    "5. The most uncertain labels (ie those with probability closest to 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This is the label for a val data\n",
    "data.val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from here we know that 'cats' is label 0 and 'dogs' is label 1.\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# this gives prediction for validation set. Predictions are in log scale\n",
    "log_preds = learn.predict()\n",
    "log_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(log_preds, axis=1)  # from log probabilities to 0 or 1\n",
    "probs = np.exp(log_preds[:,1])        # pr(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rand_by_mask(mask): return np.random.choice(np.where(mask)[0], 4, replace=False)\n",
    "def rand_by_correct(is_correct): return rand_by_mask((preds == data.val_y)==is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_val_with_title(idxs, title):\n",
    "    imgs = np.stack([data.val_ds[x][0] for x in idxs])\n",
    "    title_probs = [probs[x] for x in idxs]\n",
    "    print(title)\n",
    "    return plots(data.val_ds.denorm(imgs), rows=1, titles=title_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=1, titles=None):\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_img_id(ds, idx): return np.array(PIL.Image.open(PATH+ds.fnames[idx]))\n",
    "\n",
    "def plot_val_with_title(idxs, title):\n",
    "    imgs = [load_img_id(data.val_ds,x) for x in idxs]\n",
    "    title_probs = [probs[x] for x in idxs]\n",
    "    print(title)\n",
    "    return plots(imgs, rows=1, titles=title_probs, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 1. A few correct labels at random\n",
    "plot_val_with_title(rand_by_correct(True), \"Correctly classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 2. A few incorrect labels at random\n",
    "plot_val_with_title(rand_by_correct(False), \"Incorrectly classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def most_by_mask(mask, mult):\n",
    "    idxs = np.where(mask)[0]\n",
    "    return idxs[np.argsort(mult * probs[idxs])[:4]]\n",
    "\n",
    "def most_by_correct(y, is_correct): \n",
    "    mult = -1 if (y==1)==is_correct else 1\n",
    "    return most_by_mask((preds == data.val_y)==is_correct & (data.val_y == y), mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, True), \"Most correct Noninvasive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, True), \"Most correct Invasive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, False), \"Most incorrect Noninvasive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, False), \"Most incorrect Invasive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(np.abs(probs -0.5))[:4]\n",
    "plot_val_with_title(most_uncertain, \"Most uncertain predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Choosing a learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The *learning rate* determines how quickly or how slowly you want to update the *weights* (or *parameters*). Learning rate is one of the most difficult parameters to set, because it significantly affect model performance.\n",
    "\n",
    "The method `learn.lr_find()` helps you find an optimal learning rate. It uses the technique developed in the 2015 paper [Cyclical Learning Rates for Training Neural Networks](http://arxiv.org/abs/1506.01186), where we simply keep increasing the learning rate from a very small value, until the loss starts decreasing. We can plot the learning rate across batches to see what this looks like.\n",
    "\n",
    "We first create a new learner, since we want to know how to set the learning rate for a new (untrained) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, precompute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lrf=learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our `learn` object contains an attribute `sched` that contains our learning rate scheduler, and has some convenient plotting functionality including this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that in the previous plot *iteration* is one iteration (or *minibatch*) of SGD. In one epoch there are \n",
    "(num_train_samples/num_iterations) of SGD.\n",
    "\n",
    "We can see the plot of loss versus learning rate to see where our loss stops decreasing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The loss is still clearly improving at lr=1e-2 (0.01), so that's what we use. Note that the optimal learning rate can change as we training the model, so you may want to re-run this function from time to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you try training for more epochs, you'll notice that we start to *overfit*, which means that our model is learning to recognize the specific images in the training set, rather than generalizaing such that we also get good results on the validation set. One way to fix this is to effectively create more data, through *data augmentation*. This refers to randomly changing the images in ways that shouldn't impact their interpretation, such as horizontal flipping, zooming, and rotating.\n",
    "\n",
    "We can do this by passing `aug_tfms` (*augmentation transforms*) to `tfms_from_model`, with a list of functions to apply that randomly change the image however we wish. For photos that are largely taken from the side (e.g. most photos of dogs and cats, as opposed to photos taken from the top down, such as satellite imagery) we can use the pre-defined list of functions `transforms_side_on`. We can also specify random zooming of images up to specified scale by adding the `max_zoom` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(resnet34, sz, aug_tfms=transforms_side_on, max_zoom=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def get_augs():\n",
    "#     data = ImageClassifierData.from_paths(PATH, bs=2, tfms=tfms, num_workers=1)\n",
    "#     x,_ = next(iter(data.aug_dl))\n",
    "#     return data.trn_ds.denorm(x)[1]\n",
    "\n",
    "n = df.shape[0]-1\n",
    "val_idxs = get_cv_idxs(n)\n",
    "def get_augs():\n",
    "    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "    data = ImageClassifierData.from_csv(path=PATH, folder='train', csv_fname=csv_path, num_workers=2, \n",
    "                                        tfms=tfms, suffix='.jpg', test_name='test', val_idxs=val_idxs, skip_header=True, bs=2)\n",
    "    \n",
    "    x,_ = next(iter(data.aug_dl))\n",
    "    return data.trn_ds.denorm(x)[1]\n",
    "#     return data.resize(sz, 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ims = np.stack([get_augs() for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plots(ims, rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's create a new `data` object that includes this augmentation in the transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = get_data(sz, 64)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.precompute=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By default when we create a learner, it sets all but the last layer to *frozen*. That means that it's still only updating the weights in the last layer when we call `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 3, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our validation loss isn't improving much, so there's probably no point further training the last layer on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we've got a pretty good model at this point, we might want to save it so we can load it again later without training it from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('600_lastlayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('600_lastlayer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fine-tuning and differential learning rate annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we have a good final layer trained, we can try fine-tuning the other layers. To tell the learner that we want to unfreeze the remaining layers, just call (surprise surprise!) `unfreeze()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that the other layers have *already* been trained to recognize imagenet photos (whereas our final layers where randomly initialized), so we want to be careful of not destroying the carefully tuned weights that are already there.\n",
    "\n",
    "Generally speaking, the earlier layers (as we've seen) have more general-purpose features. Therefore we would expect them to need less fine-tuning for new datasets. For this reason we will use different learning rates for different layers: the first few layers will be at 1e-4, the middle layers at 1e-3, and our FC layers we'll leave at 1e-2 as before. We refer to this as *differential learning rates*, although there's no standard name for this techique in the literature that we're aware of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr=np.array([1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another trick we've used here is adding the `cycle_mult` parameter. Take a look at the following chart, and see if you can figure out what the parameter is doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that's what being plotted above is the learning rate of the *final layers*. The learning rates of the earlier layers are fixed at the same multiples of the final layer rates as we initially requested (i.e. the first layers have 100x smaller, and middle layers 10x smaller learning rates, since we set `lr=np.array([1e-4,1e-3,1e-2])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('600_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('600_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is something else we can do with data augmentation: use it at *inference* time (also known as *test* time). Not surprisingly, this is known as *test time augmentation*, or just *TTA*.\n",
    "\n",
    "TTA simply makes predictions not just on the images in your validation set, but also makes predictions on a number of randomly augmented versions of them too (by default, it uses the original image along with 4 randomly augmented versions). It then takes the average prediction from these images, and uses that. To use TTA on the validation set, we can use the learner's `TTA()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_preds_train,y_train = learn.TTA()\n",
    "\n",
    "# probs = np.mean(np.exp(log_preds),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_preds_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.mean(np.exp(log_preds_train),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accuracy(probs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I generally see about a 10-20% reduction in error on this dataset when using TTA at this point, which is an amazing result for such a quick and easy technique!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = np.argmax(probs, axis=1)\n",
    "probs = probs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A common way to analyze the result of a classification model is to use a [confusion matrix](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/). Scikit-learn has a convenient function we can use for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can just print out the confusion matrix, or we can show a graphical view (which is mainly useful for dependents with a larger number of categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Looking at pictures again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(0, False), \"Most incorrect Noninvasive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_val_with_title(most_by_correct(1, False), \"Most incorrect Invasive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds,y = learn.TTA(is_test=True)\n",
    "probs = np.mean(np.exp(log_preds),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.test_ds.fnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.DataFrame(probs)\n",
    "ds.columns = data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.insert(0, 'name', [o[len('test/'):-len('.jpg')] for o in data.test_ds.fnames])\n",
    "ds.drop(columns='0', axis=1, inplace=True)\n",
    "ds.rename(columns={'1':'invasive'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBM_FOLDER = f'{PATH}subm/'\n",
    "SUBM_FILE = f'{SUBM_FOLDER}subm.gz'\n",
    "os.makedirs(SUBM_FOLDER, exist_ok=True)\n",
    "ds.to_csv(SUBM_FILE, compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path = PATH+'test_labels.csv'\n",
    "ds.to_csv(test_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink(SUBM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining test data predictions and running model again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_csv_path)\n",
    "df_train = pd.read_csv(train_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['invasive'] = df_test.invasive.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.name = df_test.name.apply(lambda x: 'test-'+str(x), convert_dtype=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_test, df_train])\n",
    "print(df_all.shape)\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_path = PATH+'all_labels.csv'\n",
    "df_all.to_csv(all_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move images to all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir \"{PATH}all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp \"{PATH}train/\"* \"{PATH}all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append \"test-\" suffix to test images and move to all folder\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "_, _, filenames = next(os.walk(f'{PATH}test'))\n",
    "for f in filenames:\n",
    "#     print(f'{PATH}test/{f}')\n",
    "#     print(f'{PATH}all/test-{f}')\n",
    "    shutil.copyfile(f'{PATH}test/{f}', f'{PATH}all/test-{f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all.shape)\n",
    "_, _, filenames = next(os.walk(f'{PATH}all'))\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running data on new frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Uncomment the below if you need to reset your precomputed activations\n",
    "# !rm -rf {PATH}tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_path = PATH+'all_labels.csv'\n",
    "df_all = pd.read_csv(all_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = df_all.shape[0]-1\n",
    "val_idxs = get_cv_idxs(n, val_pct=.1)\n",
    "sz = 520\n",
    "arch = resnet50\n",
    "def get_data(sz,bs):\n",
    "    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "    data = ImageClassifierData.from_csv(path=PATH, folder='all', csv_fname=all_csv_path, num_workers=4, \n",
    "                                        tfms=tfms, suffix='.jpg', test_name='test', val_idxs=val_idxs, skip_header=True, bs=bs)\n",
    "    return data.resize(sz, 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d121fcfc3d4bc1ac21a4625a4db19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = get_data(sz, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(arch, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b7dd7cfaf34a59952234c5a851f6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/108 [00:01<01:41,  1.04it/s, loss=1.04]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 92/108 [00:59<00:10,  1.54it/s, loss=2.42] \n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b702eb828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765eaf1e03b345e08e4fc35c9eba79b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.      0.22726 0.11947 0.95312]                            \n",
      "[1.      0.1807  0.09677 0.97118]                            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit(1e-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.pretrained=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43261544330f4e76948f2762fcdf7c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.      0.15333 0.0975  0.96319]                            \n",
      "[1.      0.1497  0.0881  0.96875]                            \n",
      "[2.      0.14803 0.08144 0.96597]                            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit(1e-2, 3, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(f'{sz}_trainandtest_last_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(f'{sz}_trainandtest_last_layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that the other layers have *already* been trained to recognize imagenet photos (whereas our final layers where randomly initialized), so we want to be careful of not destroying the carefully tuned weights that are already there.\n",
    "\n",
    "Generally speaking, the earlier layers (as we've seen) have more general-purpose features. Therefore we would expect them to need less fine-tuning for new datasets. For this reason we will use different learning rates for different layers: the first few layers will be at 1e-4, the middle layers at 1e-3, and our FC layers we'll leave at 1e-2 as before. We refer to this as *differential learning rates*, although there's no standard name for this techique in the literature that we're aware of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr=np.array([1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67f7fd9de104e84810372c8c3545140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.      0.15551 0.06094 0.97899]                            \n",
      "[1.      0.10061 0.05781 0.97899]                            \n",
      "[2.      0.07151 0.058   0.97622]                             \n",
      "[3.      0.07292 0.04324 0.97639]                             \n",
      "[4.      0.04385 0.05513 0.97587]                             \n",
      "[5.      0.03186 0.04616 0.98385]                             \n",
      "[6.      0.03958 0.04211 0.98906]                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Another trick we've used here is adding the `cycle_mult` parameter. Take a look at the following chart, and see if you can figure out what the parameter is doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note that's what being plotted above is the learning rate of the *final layers*. The learning rates of the earlier layers are fixed at the same multiples of the final layer rates as we initially requested (i.e. the first layers have 100x smaller, and middle layers 10x smaller learning rates, since we set `lr=np.array([1e-4,1e-3,1e-2])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('660_trainandtest_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('660_trainandtest_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is something else we can do with data augmentation: use it at *inference* time (also known as *test* time). Not surprisingly, this is known as *test time augmentation*, or just *TTA*.\n",
    "\n",
    "TTA simply makes predictions not just on the images in your validation set, but also makes predictions on a number of randomly augmented versions of them too (by default, it uses the original image along with 4 randomly augmented versions). It then takes the average prediction from these images, and uses that. To use TTA on the validation set, we can use the learner's `TTA()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_preds_train,y_train = learn.TTA()\n",
    "\n",
    "# probs = np.mean(np.exp(log_preds),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    }
   ],
   "source": [
    "log_preds,y = learn.TTA(is_test=True)\n",
    "probs = np.mean(np.exp(log_preds),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1531, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.test_ds.fnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.DataFrame(probs)\n",
    "ds.columns = data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.998082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1127</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>962</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>0.992644</td>\n",
       "      <td>0.007356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1366</td>\n",
       "      <td>0.999170</td>\n",
       "      <td>0.000830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name       0.0       1.0\n",
       "0   146  0.001918  0.998082\n",
       "1  1127  0.999982  0.000018\n",
       "2   962  0.000006  0.999995\n",
       "3    82  0.992644  0.007356\n",
       "4  1366  0.999170  0.000830"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.insert(0, 'name', [o[len('test/'):-len('.jpg')] for o in data.test_ds.fnames])\n",
    "ds.drop(columns='0.0', axis=1, inplace=True)\n",
    "ds.rename(columns={'1.0':'invasive'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>invasive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>0.998082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1127</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>962</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>0.007356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1366</td>\n",
       "      <td>0.000830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  invasive\n",
       "0   146  0.998082\n",
       "1  1127  0.000018\n",
       "2   962  0.999995\n",
       "3    82  0.007356\n",
       "4  1366  0.000830"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBM_FOLDER = f'{PATH}subm/'\n",
    "SUBM_FILE = f'{SUBM_FOLDER}subm_all.gz'\n",
    "os.makedirs(SUBM_FOLDER, exist_ok=True)\n",
    "ds.to_csv(SUBM_FILE, compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path = PATH+'test_labels.csv'\n",
    "ds.to_csv(test_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/invasivespecies/subm/subm_all.gz' target='_blank'>data/invasivespecies/subm/subm_all.gz</a><br>"
      ],
      "text/plain": [
       "/home/paperspace/fastai/courses/dl1/data/invasivespecies/subm/subm_all.gz"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(SUBM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_clipped = ds.copy()\n",
    "ds_clipped['invasive'] = ds_clipped.invasive.clip(lower=0.05, upper=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1531, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_clipped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBM_FILE_CLIPPED = f'{SUBM_FOLDER}subm_all_clipped.gz'\n",
    "os.makedirs(SUBM_FOLDER, exist_ok=True)\n",
    "ds_clipped.to_csv(SUBM_FILE_CLIPPED, compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/invasivespecies/subm/subm_all_clipped.gz' target='_blank'>data/invasivespecies/subm/subm_all_clipped.gz</a><br>"
      ],
      "text/plain": [
       "/home/paperspace/fastai/courses/dl1/data/invasivespecies/subm/subm_all_clipped.gz"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(SUBM_FILE_CLIPPED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Review: easy steps to train a world-class image classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Enable data augmentation, and precompute=True\n",
    "1. Use `lr_find()` to find highest learning rate where loss is still clearly improving\n",
    "1. Train last layer from precomputed activations for 1-2 epochs\n",
    "1. Train last layer with data augmentation (i.e. precompute=False) for 2-3 epochs with cycle_len=1\n",
    "1. Unfreeze all layers\n",
    "1. Set earlier layers to 3x-10x lower learning rate than next higher layer\n",
    "1. Use `lr_find()` again\n",
    "1. Train full network with cycle_mult=2 until over-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips and Tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tfms,val_tfms = tfms_from_model(arch, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = val_tfms(Image.open(PATH+fn))\n",
    "preds = learn.predict_array(im[None])\n",
    "np.argmax(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
